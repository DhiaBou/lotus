{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:33.839889Z",
     "start_time": "2025-09-06T12:39:28.549117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import lotus\n",
    "from join_optimizer.lotus.evaluate import evaluate_filter\n",
    "from lotus.dtype_extensions import ImageArray\n",
    "from lotus.fts_store.db_fts_store import SQLiteFTSStore\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "from lotus.types import BayesStoppingArgs\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "from lotus.vector_store import FaissVS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LOAD_INDEX = True\n",
    "\n",
    "OFF_DATASET_DIR = os.getenv(\"OFF_DATASET_DIR\")\n",
    "\n",
    "OFF_PARQUET = os.path.join(OFF_DATASET_DIR, \"products.parquet\")\n",
    "OFF_IMAGES_DIR = os.path.join(OFF_DATASET_DIR, \"images\")\n",
    "DATASET_CAPTION_DB_BLIP = os.path.join(OFF_DATASET_DIR,\n",
    "                                       \"off_uk_top2000_with_images_caps_blip-image-captioning-large.db\")\n",
    "DATASET_CAPTION_DB_INSTRUCTBLIP = os.path.join(OFF_DATASET_DIR,\n",
    "                                               \"off_uk_top2000_with_images_caps_instructblip-flan-t5-xl.db\")\n",
    "DATASET_CAPTION_DB_GPT_5_NANO = os.path.join(OFF_DATASET_DIR, \"llm.db\")\n",
    "\n",
    "stats = {}\n",
    "\n",
    "sample_size_percentage = 100\n",
    "seed = 80\n",
    "df = duckdb.query(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM parquet_scan('{OFF_PARQUET}')\n",
    "\n",
    "    USING SAMPLE {sample_size_percentage} PERCENT (reservoir, {seed})\n",
    "    ORDER BY code ASC\n",
    "\n",
    "\"\"\").to_df()\n",
    "\n",
    "df[\"image\"] = ImageArray(df[\"code\"].apply(lambda i: os.path.join(OFF_IMAGES_DIR, f\"{str(i)}.jpg\")))\n",
    "df[\"image_url\"] = ImageArray(df[\"image_front_url\"]\n",
    "                             # .apply(lambda i: i.replace('.400.', '.full.'))\n",
    "                             )\n"
   ],
   "id": "bd9b009019fd13ee",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhiabouassida/miniconda3/envs/lotus/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating the index",
   "id": "fa1051743c8b80ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:34.930751Z",
     "start_time": "2025-09-06T12:39:33.844994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpt_5_nano = LM(\"gpt-5-nano\")\n",
    "gpt_5_mini = LM(\"gpt-5-mini\")\n",
    "\n",
    "gpt_5_____sure = LM(\"gpt-5\")\n",
    "\n",
    "gpt_4o_mini = LM(\"gpt-4o-mini\")\n",
    "gpt_4o = LM(\"gpt-4o\")\n",
    "\n",
    "filter_llm = gpt_5_mini\n",
    "\n",
    "# CLIP embedding model – works for both text & image\n",
    "# rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "rm = SentenceTransformersRM(model=\"clip-ViT-L-14\", max_batch_size=32)\n",
    "\n",
    "lotus.settings.configure(lm=gpt_5_mini, helper_lm=gpt_5_nano, rm=rm, vs=FaissVS(), cs=SQLiteFTSStore())"
   ],
   "id": "78fb4d3bf0f58ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 12:39:33,846 - INFO - Load pretrained SentenceTransformer: clip-ViT-L-14\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:34.996148Z",
     "start_time": "2025-09-06T12:39:34.993424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not LOAD_INDEX:\n",
    "    df = df.sem_index(\"image\", index_dir=f\"{OFF_DATASET_DIR}/image{sample_size_percentage}_index\")\n",
    "\n"
   ],
   "id": "95d55c274350948c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:35.061632Z",
     "start_time": "2025-09-06T12:39:35.059296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.load_sem_index(\"image\", index_dir=f\"{OFF_DATASET_DIR}/image{sample_size_percentage}_index\")\n",
    "df = df.load_sem_index(\"image_url\", index_dir=f\"{OFF_DATASET_DIR}/image{sample_size_percentage}_index\")"
   ],
   "id": "4b4592cea0da91d5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:35.114422Z",
     "start_time": "2025-09-06T12:39:35.110849Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.sample(n=100, random_state=seed)\n",
   "id": "33afbc92512859af",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompt",
   "id": "a6847d8826c66d6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:35.171197Z",
     "start_time": "2025-09-06T12:39:35.168744Z"
    }
   },
   "cell_type": "code",
   "source": "prompt = \"sugar free dairy product\"",
   "id": "58de5cf236a3929f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "stats helper",
   "id": "117b5a57682323dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:35.222942Z",
     "start_time": "2025-09-06T12:39:35.220048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_stats(method: str, _metrics: dict[str, Any] = None):\n",
    "    if _metrics is None:\n",
    "        _metrics = {}\n",
    "    stats[method] = _metrics\n",
    "    stats[method][\"Virtual Cost\"] = filter_llm.stats.virtual_usage.total_cost\n",
    "    stats[method][\"Virtual Tokens\"] = filter_llm.stats.virtual_usage.total_tokens\n",
    "    filter_llm.reset_stats()\n"
   ],
   "id": "612876ae5bde16a4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full LLM calls",
   "id": "b3ed2f3f83212c79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:46.541344Z",
     "start_time": "2025-09-06T12:39:35.283248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"full LLM calls\"\n",
    "\n",
    "df_resd_llm = df.sem_filter(prompt, col_li=[\"image\"], return_stats=False)\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_llm,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])"
   ],
   "id": "363fa372a1473c09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 100/100 LM calls [00:11<00:00,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.04542360000000001, 'Virtual Tokens': 94472}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Binary search filter",
   "id": "d8c92a6f7ed2a023"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:51.275734Z",
     "start_time": "2025-09-06T12:39:46.591342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"binary search filter\"\n",
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "df_resd_binary_s = df.sem_filter(prompt, col_li=[\"image\"], cascade_args=cascade_args,\n",
    "                                 return_stats=True, find_top_k=True)\n"
   ],
   "id": "9537b5c0d298aeb9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.49s/it]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:39:51.332237Z",
     "start_time": "2025-09-06T12:39:51.327357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_binary_s,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])"
   ],
   "id": "29256cb374be9c7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.00058775, 'Virtual Tokens': 1371}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sampling",
   "id": "9ca19bcff2c204c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:12.207965Z",
     "start_time": "2025-09-06T12:39:51.391813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"Lotus sampling\"\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.95,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    "    cascade_IS_weight=1,\n",
    "    cascade_num_calibration_quantiles=100,\n",
    "    failure_probability=0.1,\n",
    "    cascade_IS_random_seed=114,\n",
    ")\n",
    "filter_llm.reset_stats()\n",
    "df_resd_lotus = df.sem_filter(prompt, col_li=[\"image\"], cascade_args=cascade_args, return_stats=False,\n",
    "                              find_top_k=False)\n",
    "filter_llm.print_total_usage()\n",
    "\n"
   ],
   "id": "183a4c385a5b298b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running oracle for threshold learning: 100%|██████████ 10/10 LM calls [00:04<00:00,  2.23it/s]\n",
      "2025-09-06 12:39:56,047 - INFO - Sample recall: 0.0\n",
      "2025-09-06 12:39:56,048 - INFO - Sample precision: 0.0\n",
      "2025-09-06 12:39:56,048 - INFO - Learned cascade thresholds: (1.0, 0)\n",
      "2025-09-06 12:39:56,048 - INFO - Num routed to smaller model: 0\n",
      "Running predicate evals with oracle LM: 100%|██████████ 100/100 LM calls [00:16<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Usage Statistics ===\n",
      "Virtual  = Total usage if no caching was used\n",
      "Physical = Actual usage with caching applied\n",
      "\n",
      "Virtual Cost:     $0.049806\n",
      "Physical Cost:    $0.049806\n",
      "Virtual Tokens:   103,522\n",
      "Physical Tokens:  103,522\n",
      "Cache Hits:       0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:12.292136Z",
     "start_time": "2025-09-06T12:40:12.287326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_lotus,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])"
   ],
   "id": "1eb01808b855ebc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.04980649999999999, 'Virtual Tokens': 103522}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Caption Search BLIP\n",
   "id": "baebf16943022f81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:12.358980Z",
     "start_time": "2025-09-06T12:40:12.351735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"Caption blip\"\n",
    "df = df.sem_captions_index.attach_index(\"image\", index_dir=DATASET_CAPTION_DB_BLIP)\n",
    "df = df.sem_captions_index.load(\"image\")\n",
    "df_resd_blip = df.sem_captions_index.search(prompt, \"image\")"
   ],
   "id": "e4c7ce345da9c1a4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:12.411596Z",
     "start_time": "2025-09-06T12:40:12.407157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_blip,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])\n"
   ],
   "id": "1b5059284b77f31c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "da7795b0f8b9cfe6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### with prompt augmentation",
   "id": "d85bf68fb7231f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:12.466029Z",
     "start_time": "2025-09-06T12:40:12.463389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def augment_prompt(prompt, augmentation_prompt):\n",
    "    prompt_as_df = pd.DataFrame({\"query\": [prompt]})\n",
    "    return prompt_as_df.sem_map(augmentation_prompt, suffix=\"augmented_prompt\")[\"augmented_prompt\"][0].replace(\"'\",\n",
    "                                                                                                               \" \").replace(\n",
    "        \"-\", \" \")\n"
   ],
   "id": "caeb090d4f51aeff",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:25.882959Z",
     "start_time": "2025-09-06T12:40:12.514133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_augmentation_prompt = \"you will receive a {query} to do a full text search filter on a dataset. since the search is sintactical, provide 10 other prompts similar to the one provided, so that similar items can be obtained. Separate the results with a simple space and without delimiters like \\\" or \\«. only respond with the result.\"\n",
    "\n",
    "prompt_augmentation_prompt = \"\"\"\n",
    "You will receive a plain-language search {query} and must return a SINGLE valid SQLite FTS5 MATCH expression (the right-hand side of `... MATCH <expr>`). Return ONLY the expression, with no quotes around the whole thing, no SQL, no code fences, and no explanations.\n",
    "\n",
    "REQUIREMENTS\n",
    "1) Output must be valid FTS5 boolean syntax using ONLY: parentheses `()`, `AND`, `OR`, `NOT`, double-quoted phrases, and (optionally) `NEAR` when allowed below. Do NOT use field qualifiers, weights, or other SQL.\n",
    "2) Group synonyms/near-lexicon with OR inside parentheses. Use AND between concept buckets.\n",
    "   - Example shape: `(concept1_a OR concept1_b OR \"concept1 phrase\") AND (concept2_a OR concept2_b) ...`\n",
    "3) Expand the user_query into 2–5 concept buckets (meaningful facets like style, color/tone, item types, descriptors, etc.). Inside each bucket, include common synonyms, close lexical variants, and singular/plural irregulars. The database already handles case, diacritics, and stemming—only add explicit variants when helpful (e.g., \"tuxedo OR tuxedos\", \"black-tie OR \\\"black tie\\\"\").\n",
    "6) Phrases must use double quotes (e.g., \"black tie\"). Do NOT wrap the entire output in quotes.\n",
    "7) Avoid `*` wildcards unless the input explicitly asks for prefix search.\n",
    "\n",
    "OUTPUT\n",
    "- Only the MATCH expression\n",
    "\"\"\"\n",
    "\n",
    "augmented_prompt = augment_prompt(prompt, prompt_augmentation_prompt)\n",
    "print(augmented_prompt)"
   ],
   "id": "58f346b66ab56cbc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping: 100%|██████████ 1/1 LM calls [00:13<00:00, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"sugar free\" OR \"sugar free\" OR sugarfree OR \"no sugar\" OR \"no sugar added\" OR \"no sugar\" OR unsweetened OR sugarless OR \"low sugar\" OR \"reduced sugar\") AND (dairy OR \"dairy product\" OR \"dairy products\" OR milk OR \"milk product\" OR cheese OR cheeses OR yogurt OR yoghurt OR yogurts OR yoghurts OR butter OR cream OR \"ice cream\" OR icecream OR \"cream cheese\" OR kefir OR buttermilk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:25.939324Z",
     "start_time": "2025-09-06T12:40:25.935326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"caption blip with prompt augmentation\"\n",
    "df_resd_blip_augmented = df.sem_captions_index.search(augmented_prompt, \"image\")"
   ],
   "id": "8fd0baca49b616ae",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:25.993562Z",
     "start_time": "2025-09-06T12:40:25.988787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_blip,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])\n"
   ],
   "id": "f908d5fb2a5b105d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0021237499999999998, 'Virtual Tokens': 1376}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Caption Search INSTRUCTBLIP",
   "id": "e0b2954c060e2f46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:26.049983Z",
     "start_time": "2025-09-06T12:40:26.042941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"instruct blip\"\n",
    "df = df.sem_captions_index.attach_index(\"image\", index_dir=DATASET_CAPTION_DB_INSTRUCTBLIP)\n",
    "df = df.sem_captions_index.load(\"image\")\n",
    "df_resd_instructblip = df.sem_captions_index.search(prompt, \"image\")"
   ],
   "id": "b45d7a3fd34c8e7",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:26.098884Z",
     "start_time": "2025-09-06T12:40:26.095013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_instructblip,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])\n"
   ],
   "id": "63f61181d594b0b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Augmented",
   "id": "bec4ba680259c8fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:26.157199Z",
     "start_time": "2025-09-06T12:40:26.152485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"instruct blip + prompt augmentation\"\n",
    "df_resd_instructblip_augmented = df.sem_captions_index.search(augmented_prompt, \"image\")"
   ],
   "id": "5c404d1ac979e76f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:26.211255Z",
     "start_time": "2025-09-06T12:40:26.206512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_instructblip_augmented,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])\n"
   ],
   "id": "1ba43f3f52a271d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pass through small model",
   "id": "a8763954daab6eab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:38.922987Z",
     "start_time": "2025-09-06T12:40:26.262369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"call LLM on instruct blip captions\"\n",
    "df_resd_captions_small_model = df.sem_filter(\n",
    "    prompt, col_li=[\"image_cap\"])\n"
   ],
   "id": "d8472c7e97fe50c0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 100/100 LM calls [00:12<00:00,  7.91it/s]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:39.008676Z",
     "start_time": "2025-09-06T12:40:39.003553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_captions_small_model,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])"
   ],
   "id": "e2c6a5b6d081b2a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.03265499999999997, 'Virtual Tokens': 28588}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# gpt-5-nano Captions",
   "id": "51e5fb1150ee2fdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:39.064671Z",
     "start_time": "2025-09-06T12:40:39.057351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"Gpt-5-nano captions\"\n",
    "df = df.sem_captions_index.attach_index(\"image\", index_dir=DATASET_CAPTION_DB_GPT_5_NANO)\n",
    "df = df.sem_captions_index.load(\"image\")\n",
    "df_resd_llm_captions = df.sem_captions_index.search(prompt, \"image\")"
   ],
   "id": "e78b83040647cdca",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:39.114300Z",
     "start_time": "2025-09-06T12:40:39.109726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_llm_captions,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])\n"
   ],
   "id": "3722462420815de5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Augmented",
   "id": "cb8907e448596f5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:39.167339Z",
     "start_time": "2025-09-06T12:40:39.159652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"Gpt-5-nano captions + prompt augmentation\"\n",
    "df_resd_llm_captions_augmented = df.sem_captions_index.search(augmented_prompt, \"image\")\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_llm_captions_augmented,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])\n"
   ],
   "id": "c44d709b0f9533b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 1, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Pass Captions through llm",
   "id": "bf759c164736c825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:40:47.635926Z",
     "start_time": "2025-09-06T12:40:39.209896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"pass Gpt-5-nano captions through model\"\n",
    "df_resd_llm_captions_small_model = df.sem_filter(\n",
    "    prompt, col_li=[\"image_cap\"])\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_llm_captions_small_model,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])"
   ],
   "id": "39a152832a4ba1d8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 100/100 LM calls [00:08<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.03495475000000001, 'Virtual Tokens': 34651}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bayesian stopping",
   "id": "9725ba61acd5cc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:41:01.564401Z",
     "start_time": "2025-09-06T12:40:47.719290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "method_name = \"rolling beta posterior\"\n",
    "bayes_args = BayesStoppingArgs(\n",
    "    block_size=40,\n",
    "    min_depth=20,\n",
    "    max_depth=None,\n",
    "    delta=0.9,\n",
    "    discount=0.9,\n",
    "    alpha0=10.0,\n",
    "    beta0=1.0,\n",
    "    verifier_recall=1.0,\n",
    "    default=True,\n",
    "    verbose=True)\n",
    "\n",
    "df_resd_bayes = df.sem_filter(prompt, col_li=[\"image\"], cascade_args=cascade_args, find_top_k=False, bayesian_scan=True,\n",
    "                              bayes_stopping_args=bayes_args)\n",
    "filter_llm.print_total_usage()"
   ],
   "id": "4491fec145b7a5b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scan] Starting scan_with_bayesian_stopping (no bins)\n",
      "[scan] n_docs=100, block_size=40, min_depth=20, max_depth=None\n",
      "[scan] delta=0.9 (continue while P(next block ≥1 positive) ≥ delta)\n",
      "[scan] discount=0.9, alpha0=10.0, beta0=1.0\n",
      "[scan] verifier_recall=1.0, default=True\n",
      "\n",
      "[scan] ── Processing block ─────────────────────────────────────────\n",
      "[scan] Block indices: [0:40) (size=40)\n",
      "[scan] Calling sem_filter(...) on this block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 40/40 LM calls [00:06<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scan] Discounting prior evidence by factor 0.9\n",
      "[scan] Before discount | succ=0.000 fail=0.000\n",
      "[scan] After  discount | succ=0.000 fail=0.000\n",
      "[scan] sem_filter tallies in this block: pos=0, neg=40\n",
      "[scan] Updated posteriors    | succ=0.000 fail=40.000\n",
      "[scan] Look-ahead next block indices: [40:80) (size=40)\n",
      "[scan] Posterior alpha=10.000, beta=41.000, P(next block ≥1 pos) = 0.998204\n",
      "[scan] Continuing: 0.998204 ≥ delta=0.9\n",
      "\n",
      "[scan] ── Processing block ─────────────────────────────────────────\n",
      "[scan] Block indices: [40:80) (size=40)\n",
      "[scan] Calling sem_filter(...) on this block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 40/40 LM calls [00:07<00:00,  5.51it/s]\n",
      "2025-09-06 12:41:01,561 - INFO - Bayesian scan stopped after 80 of 100 items\n",
      "2025-09-06 12:41:01,561 - INFO - Found 0 positives\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scan] Discounting prior evidence by factor 0.9\n",
      "[scan] Before discount | succ=0.000 fail=40.000\n",
      "[scan] After  discount | succ=0.000 fail=36.000\n",
      "[scan] sem_filter tallies in this block: pos=0, neg=40\n",
      "[scan] Updated posteriors    | succ=0.000 fail=76.000\n",
      "[scan] Look-ahead next block indices: [80:100) (size=20)\n",
      "[scan] Posterior alpha=10.000, beta=77.000, P(next block ≥1 pos) = 0.888838\n",
      "[scan] Stopping: 0.888838 < delta=0.9\n",
      "\n",
      "[scan] ── Final summary ───────────────────────────────────────────\n",
      "[scan] Scanned stop_index=80 docs out of n=100\n",
      "[scan] Positives found: 0 | Negatives (scanned prefix): 80\n",
      "[scan] P(any positive in next block) at stop: 0.888838\n",
      "\n",
      "=== Usage Statistics ===\n",
      "Virtual  = Total usage if no caching was used\n",
      "Physical = Actual usage with caching applied\n",
      "\n",
      "Virtual Cost:     $0.038481\n",
      "Physical Cost:    $0.038481\n",
      "Virtual Tokens:   77,316\n",
      "Physical Tokens:  77,316\n",
      "Cache Hits:       0\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:41:01.651705Z",
     "start_time": "2025-09-06T12:41:01.647377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_bayes,\n",
    "    id_column='code'\n",
    ")\n",
    "add_stats(method_name, metrics)\n",
    "print(stats[method_name])\n"
   ],
   "id": "e9fa313251c2a875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.038480999999999994, 'Virtual Tokens': 77316}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T12:42:07.942887Z",
     "start_time": "2025-09-06T12:42:07.939966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for _method_name, _stats in stats.items():\n",
    "    print(_method_name)\n",
    "    print(_stats)"
   ],
   "id": "a50c57ded66361c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full LLM calls\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.04542360000000001, 'Virtual Tokens': 94472}\n",
      "binary search filter\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.00058775, 'Virtual Tokens': 1371}\n",
      "Lotus sampling\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.04980649999999999, 'Virtual Tokens': 103522}\n",
      "Caption blip\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n",
      "caption blip with prompt augmentation\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0021237499999999998, 'Virtual Tokens': 1376}\n",
      "instruct blip\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n",
      "instruct blip + prompt augmentation\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n",
      "call LLM on instruct blip captions\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.03265499999999997, 'Virtual Tokens': 28588}\n",
      "Gpt-5-nano captions\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n",
      "Gpt-5-nano captions + prompt augmentation\n",
      "{'TP': 0, 'FP': 1, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.0, 'Virtual Tokens': 0}\n",
      "pass Gpt-5-nano captions through model\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.03495475000000001, 'Virtual Tokens': 34651}\n",
      "rolling beta posterior\n",
      "{'TP': 0, 'FP': 0, 'FN': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'Virtual Cost': 0.038480999999999994, 'Virtual Tokens': 77316}\n"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
