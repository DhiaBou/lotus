{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T17:15:15.398432Z",
     "start_time": "2025-08-28T17:15:06.564139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import duckdb\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from lotus.dtype_extensions import ImageArray\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "\n",
    "from join_optimizer.lotus.evaluate import evaluate_filter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LOAD_INDEX = True\n",
    "\n",
    "OFF_DATASET_DIR = os.getenv(\"OFF_DATASET_DIR\")\n",
    "\n",
    "OFF_PARQUET = os.path.join(OFF_DATASET_DIR, \"products.parquet\")\n",
    "OFF_IMAGES_DIR = os.path.join(OFF_DATASET_DIR, \"images\")\n",
    "DATASET_CAPTION_DB_BLIP = os.path.join(OFF_DATASET_DIR, \"off_uk_top2000_with_images_caps_blip-image-captioning-large.db\")\n",
    "DATASET_CAPTION_DB_INSTRUCTBLIP = os.path.join(OFF_DATASET_DIR, \"off_uk_top2000_with_images_caps_instructblip-flan-t5-xl.db\")\n",
    "\n",
    "sample_size_percentage = 1\n",
    "seed = 80\n",
    "df = duckdb.query(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM parquet_scan('{OFF_PARQUET}')\n",
    "\n",
    "    USING SAMPLE {sample_size_percentage} PERCENT (reservoir, {seed})\n",
    "    ORDER BY code ASC\n",
    "\n",
    "\"\"\").to_df()\n",
    "\n",
    "df[\"image\"] = ImageArray(df[\"code\"].apply(lambda i: os.path.join(OFF_IMAGES_DIR, f\"{str(i)}.jpg\")))\n",
    "df[\"image_url\"] = ImageArray(df[\"image_front_url\"]\n",
    "                             # .apply(lambda i: i.replace('.400.', '.full.'))\n",
    "                             )\n"
   ],
   "id": "bd9b009019fd13ee",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhiabouassida/miniconda3/envs/lotus/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating the index",
   "id": "fa1051743c8b80ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T17:15:18.744314Z",
     "start_time": "2025-08-28T17:15:17.191045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lotus.fts_store.db_fts_store import SQLiteFTSStore\n",
    "from lotus.vector_store import FaissVS\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "\n",
    "gpt_5_nano = LM(\"gpt-5-nano\")\n",
    "gpt_5_mini = LM(\"gpt-5-mini\")\n",
    "\n",
    "gpt_5_____sure = LM(\"gpt-5\")\n",
    "\n",
    "gpt_4o_mini = LM(\"gpt-4o-mini\")\n",
    "gpt_4o = LM(\"gpt-4o\")\n",
    "\n",
    "# CLIP embedding model – works for both text & image\n",
    "# rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "rm = SentenceTransformersRM(model=\"clip-ViT-L-14\", max_batch_size=32)\n",
    "\n",
    "lotus.settings.configure(lm=gpt_5_mini, helper_lm=gpt_5_nano, rm=rm, vs=FaissVS(), cs=SQLiteFTSStore())"
   ],
   "id": "78fb4d3bf0f58ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 17:15:17,195 - INFO - Load pretrained SentenceTransformer: clip-ViT-L-14\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T12:28:35.525711Z",
     "start_time": "2025-08-27T12:28:35.522878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not LOAD_INDEX:\n",
    "    df = df.sem_index(\"image\", index_dir=f\"{OFF_DATASET_DIR}/image{sample_size_percentage}_index\")\n",
    "\n"
   ],
   "id": "95d55c274350948c",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T12:28:37.003475Z",
     "start_time": "2025-08-27T12:28:37.000880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.load_sem_index(\"image\", index_dir=f\"{OFF_DATASET_DIR}/image{sample_size_percentage}_index\")\n",
    "df = df.load_sem_index(\"image_url\", index_dir=f\"{OFF_DATASET_DIR}/image{sample_size_percentage}_index\")"
   ],
   "id": "4b4592cea0da91d5",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T12:28:38.491893Z",
     "start_time": "2025-08-27T12:28:38.488452Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.sample(n=1000, random_state=seed)\n",
   "id": "33afbc92512859af",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompt",
   "id": "a6847d8826c66d6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T12:28:40.700124Z",
     "start_time": "2025-08-27T12:28:40.697735Z"
    }
   },
   "cell_type": "code",
   "source": "prompt = \"dark chocolate\"",
   "id": "58de5cf236a3929f",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full LLM calls",
   "id": "b3ed2f3f83212c79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T12:33:07.675478Z",
     "start_time": "2025-08-27T12:28:43.749136Z"
    }
   },
   "cell_type": "code",
   "source": "df_resd_llm = df.sem_filter(prompt, col_li=[\"image\"], return_stats=False)",
   "id": "ab5b4f2d578adba8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 1000/1000 LM calls [01:32<00:00, 10.83it/s]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Binary search filter",
   "id": "f04a103061f9897b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:29:18.774376Z",
     "start_time": "2025-08-26T19:25:12.461175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "df_resd_binary_s = df.sem_filter(prompt, col_li=[\"image\"], cascade_args=cascade_args,\n",
    "                                              return_stats=True, find_top_k=True)\n"
   ],
   "id": "b5f27a75d38cc16c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.59s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:08<00:00,  8.49s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:07<00:00,  7.73s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.54s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:08<00:00,  8.88s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:06<00:00,  6.42s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:05<00:00,  5.90s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:05<00:00,  5.04s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:08<00:00,  8.31s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.73s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:08<00:00,  8.97s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:05<00:00,  5.43s/it]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:29:18.793200Z",
     "start_time": "2025-08-26T19:29:18.787970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_binary_s,\n",
    "    id_column='code'\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "2bcff9e7eb82c12b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 20, 'FP': 1, 'FN': 16, 'precision': 0.9523809523809523, 'recall': 0.5555555555555556, 'f1': 0.7017543859649122}\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sampling",
   "id": "125def097bda0891"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:25.551628Z",
     "start_time": "2025-08-26T19:22:34.288954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.95,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    "    cascade_IS_weight=1,\n",
    "    cascade_num_calibration_quantiles=100,\n",
    "    failure_probability=0.1,\n",
    "    cascade_IS_random_seed=114,\n",
    ")\n",
    "df_resd_lotus = df.sem_filter(prompt, col_li=[\"image\"], cascade_args=cascade_args, return_stats=False,\n",
    "                                           find_top_k=False)\n"
   ],
   "id": "5663c1a89a2b452c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running oracle for threshold learning: 100%|██████████ 100/100 LM calls [00:18<00:00,  5.51it/s]\n",
      "2025-08-26 19:23:06,065 - INFO - Sample recall: 1.0\n",
      "2025-08-26 19:23:06,065 - INFO - Sample precision: 1.0\n",
      "2025-08-26 19:23:06,066 - INFO - Learned cascade thresholds: (0.2213810384273529, 0.145962193608284)\n",
      "2025-08-26 19:23:06,066 - INFO - Num routed to smaller model: 845\n",
      "Running predicate evals with oracle LM: 100%|██████████ 155/155 LM calls [00:19<00:00,  8.06it/s]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:25.609321Z",
     "start_time": "2025-08-26T19:23:25.603863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_lotus,\n",
    "    id_column='code'\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "2d6964e41fbd23f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 33, 'FP': 1, 'FN': 3, 'precision': 0.9705882352941176, 'recall': 0.9166666666666666, 'f1': 0.9428571428571428}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Caption Search BLIP\n",
   "id": "c77b547f5de8543b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:25.666096Z",
     "start_time": "2025-08-26T19:23:25.656235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.sem_captions_index.attach_index(\"image\", index_dir=DATASET_CAPTION_DB_BLIP)\n",
    "df = df.sem_captions_index.load(\"image\")\n",
    "df_resd_blip = df.sem_captions_index.search(prompt, \"image\")"
   ],
   "id": "27eaf0d074a3644",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:25.707658Z",
     "start_time": "2025-08-26T19:23:25.702514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_blip,\n",
    "    id_column='code'\n",
    ")\n",
    "print(metrics)\n"
   ],
   "id": "b5c30d6c9cf52508",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 10, 'FP': 1, 'FN': 26, 'precision': 0.9090909090909091, 'recall': 0.2777777777777778, 'f1': 0.4255319148936171}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "473565f45fc2dc74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### with prompt augmentation",
   "id": "73b375a3239309fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:25.754174Z",
     "start_time": "2025-08-26T19:23:25.751497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def augment_prompt(prompt, augmentation_prompt):\n",
    "    prompt_as_df = pd.DataFrame({\"query\": [prompt]})\n",
    "    return prompt_as_df.sem_map(augmentation_prompt, suffix=\"augmented_prompt\")[\"augmented_prompt\"][0].replace(\"'\", \" \").replace(\"-\", \" \")\n"
   ],
   "id": "7ef7223e6cd5cfe",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:37.750821Z",
     "start_time": "2025-08-26T19:23:25.798351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_augmentation_prompt = \"you will receive a {query} to do a full text search filter on a dataset. since the search is sintactical, provide 10 other prompts similar to the one provided, so that similar items can be obtained. Separate the results with a simple space and without delimiters like \\\" or \\«. only respond with the result.\"\n",
    "\n",
    "prompt_augmentation_prompt = \"\"\"\n",
    "You will receive a plain-language search {query} and must return a SINGLE valid SQLite FTS5 MATCH expression (the right-hand side of `... MATCH <expr>`). Return ONLY the expression, with no quotes around the whole thing, no SQL, no code fences, and no explanations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "REQUIREMENTS\n",
    "1) Output must be valid FTS5 boolean syntax using ONLY: parentheses `()`, `AND`, `OR`, `NOT`, double-quoted phrases, and (optionally) `NEAR` when allowed below. Do NOT use field qualifiers, weights, or other SQL.\n",
    "2) Group synonyms/near-lexicon with OR inside parentheses. Use AND between concept buckets.\n",
    "   - Example shape: `(concept1_a OR concept1_b OR \"concept1 phrase\") AND (concept2_a OR concept2_b) ...`\n",
    "3) Expand the user_query into 2–5 concept buckets (meaningful facets like style, color/tone, item types, descriptors, etc.). Inside each bucket, include common synonyms, close lexical variants, and singular/plural irregulars. The database already handles case, diacritics, and stemming—only add explicit variants when helpful (e.g., \"tuxedo OR tuxedos\", \"black-tie OR \\\"black tie\\\"\").\n",
    "4) If must_include is provided, ensure each term/phrase is present by adding extra AND groups for them (quoted as needed).\n",
    "5) If exclude is provided, append `AND NOT (...)` with OR-joined terms/phrases to filter them out.\n",
    "6) Phrases must use double quotes (e.g., \"black tie\"). Do NOT wrap the entire output in quotes.\n",
    "7) Avoid `*` wildcards unless the input explicitly asks for prefix search.\n",
    "8) Proximity:\n",
    "   - If require_proximity = true, use NEAR **only in properly nested binary form** and at most to tie TWO buckets: `((bucketA) NEAR (bucketB)) AND (bucketC) ...`. Never chain `A NEAR B NEAR C` without nesting.\n",
    "   - If require_proximity = false (default), do NOT use NEAR.\n",
    "9) Keep the expression concise (<1000 characters).\n",
    "\n",
    "OUTPUT\n",
    "- Only the MATCH expression\n",
    "\"\"\"\n",
    "\n",
    "augmented_prompt = augment_prompt(prompt, prompt_augmentation_prompt)\n",
    "print(augmented_prompt)"
   ],
   "id": "ece62139dfeb6c7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping: 100%|██████████ 1/1 LM calls [00:11<00:00, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dark OR \"darkest\" OR bitter OR bittersweet OR \"semi sweet\" OR semisweet OR \"extra dark\" OR intense) AND (chocolate OR chocolates OR \"chocolate bar\" OR \"chocolate bars\" OR cocoa OR cacao OR truffle OR bonbon)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:37.845511Z",
     "start_time": "2025-08-26T19:23:37.840154Z"
    }
   },
   "cell_type": "code",
   "source": "df_resd_blip_augmented = df.sem_captions_index.search(augmented_prompt, \"image\")\n",
   "id": "15f67c1b1b657e1d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:37.891944Z",
     "start_time": "2025-08-26T19:23:37.886823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_blip,\n",
    "    id_column='code'\n",
    ")\n",
    "print(metrics)\n"
   ],
   "id": "bf932ae00231db8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 10, 'FP': 1, 'FN': 26, 'precision': 0.9090909090909091, 'recall': 0.2777777777777778, 'f1': 0.4255319148936171}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Caption Search INSTRUCTBLIP",
   "id": "f0c39c830329f833"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T13:10:24.312507Z",
     "start_time": "2025-08-27T13:10:24.300677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.sem_captions_index.attach_index(\"image\", index_dir=DATASET_CAPTION_DB_INSTRUCTBLIP)\n",
    "df = df.sem_captions_index.load(\"image\")\n",
    "df_resd_instructblip = df.sem_captions_index.search(prompt, \"image\")"
   ],
   "id": "2c4b1a2c324df7da",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T13:10:26.196940Z",
     "start_time": "2025-08-27T13:10:26.192152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_instructblip,\n",
    "    id_column='code'\n",
    ")\n",
    "print(metrics)\n"
   ],
   "id": "2fc8a7948a54527b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 19, 'FP': 1, 'FN': 15, 'precision': 0.95, 'recall': 0.5588235294117647, 'f1': 0.7037037037037037}\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Augmented",
   "id": "b80f1075b919d32b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:38.035615Z",
     "start_time": "2025-08-26T19:23:38.030249Z"
    }
   },
   "cell_type": "code",
   "source": "df_resd_instructblip_augmented = df.sem_captions_index.search(augmented_prompt, \"image\")",
   "id": "f3b1bcbaf55eb41f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:23:38.083167Z",
     "start_time": "2025-08-26T19:23:38.077825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_instructblip_augmented,\n",
    "    id_column='code'\n",
    ")\n",
    "print(metrics)\n"
   ],
   "id": "e19ca94e4e44c2ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 20, 'FP': 1, 'FN': 16, 'precision': 0.9523809523809523, 'recall': 0.5555555555555556, 'f1': 0.7017543859649122}\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pass through small model",
   "id": "c9a184b6cbb76cd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:24:45.593157Z",
     "start_time": "2025-08-26T19:23:38.126100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_resd_captions_small_model = df.sem_filter(\n",
    "    prompt, col_li=[\"image_cap\"])"
   ],
   "id": "bc0224ce1e2a2b88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering:   0%|           0/1000 LM calls [00:00<?, ?it/s]2025-08-26 19:24:28,180 - INFO - Retrying request to /chat/completions in 0.450501 seconds\n",
      "Filtering: 100%|██████████ 1000/1000 LM calls [01:07<00:00, 14.85it/s]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T19:45:35.410398Z",
     "start_time": "2025-08-26T19:45:35.404836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=df_resd_llm,\n",
    "    filtered_df=df_resd_captions_small_model,\n",
    "    id_column='code'\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "5f87ec76523a498e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 22, 'FP': 0, 'FN': 14, 'precision': 1.0, 'recall': 0.6111111111111112, 'f1': 0.7586206896551725}\n",
      "\n",
      "=== Usage Statistics ===\n",
      "Virtual  = Total usage if no caching was used\n",
      "Physical = Actual usage with caching applied\n",
      "\n",
      "Virtual Cost:     $0.822935\n",
      "Physical Cost:    $0.822935\n",
      "Virtual Tokens:   1,451,181\n",
      "Physical Tokens:  1,451,181\n",
      "Cache Hits:       0\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
