{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e760e63f124f19b8",
   "metadata": {},
   "source": "# SEM INDEX\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T17:28:55.653098Z",
     "start_time": "2025-08-25T17:28:55.616578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "from lotus.dtype_extensions import ImageArray\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "FASHION_DATASET_DIR = os.getenv(\"FASHION_DATASET_DIR\")\n",
    "FASHION_PARQUET = os.path.join(FASHION_DATASET_DIR, \"styles.parquet\")\n",
    "FASHION_DETAILS_PARQUET = os.path.join(FASHION_DATASET_DIR, \"styles_details.parquet\")\n",
    "FASHION_IMAGES_DIR = os.path.join(FASHION_DATASET_DIR, \"images\")\n",
    "DATASET_CAPTION_DB = os.path.join(FASHION_DATASET_DIR, \"fashion_dataset_caps_blip-image-captioning-large.db\")\n",
    "\n",
    "sample_size_percentage = 100\n",
    "seed = 80\n",
    "df = duckdb.query(f\"\"\"\n",
    "with images as (\n",
    "    SELECT *\n",
    "    FROM parquet_scan('{FASHION_PARQUET}')\n",
    "    USING SAMPLE {sample_size_percentage} PERCENT (reservoir, {seed})\n",
    "    )\n",
    "    select\n",
    "     images.id ,images.subcategory, images.articletype, images.basecolour, details.price, images.productDisplayName,\n",
    "     -- styleimages.default.resolutions.\"360X480\"  as imageURL\n",
    "     styleimages.default.imageURL  as imageURL\n",
    "    -- *\n",
    "    from images, parquet_scan('{FASHION_DETAILS_PARQUET}') details\n",
    "    where images.id = details.id\n",
    "    -- and details.price <1000\n",
    "    order by images.id\n",
    "\"\"\").to_df()\n",
    "\n",
    "df[\"image\"] = ImageArray(df[\"id\"].apply(lambda i: os.path.join(FASHION_IMAGES_DIR, f\"{int(i)}.jpg\")))\n",
    "df[\"image_url\"] = ImageArray(df[\"imageURL\"])\n",
    "\n",
    "\n"
   ],
   "id": "bd9b009019fd13ee",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating the index",
   "id": "fa1051743c8b80ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T17:28:59.539774Z",
     "start_time": "2025-08-25T17:28:58.406948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lotus.fts_store.db_fts_store import SQLiteFTSStore\n",
    "from lotus.vector_store import FaissVS\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "\n",
    "gpt_4o_mini = LM(\"gpt-4o-mini\")\n",
    "gpt_4o = LM(\"gpt-4o\")\n",
    "\n",
    "# CLIP embedding model – works for both text & image\n",
    "# rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "rm  = SentenceTransformersRM(model=\"clip-ViT-L-14\", max_batch_size=32)\n",
    "\n",
    "lotus.settings.configure(lm=gpt_4o, helper_lm=gpt_4o_mini, rm=rm, vs=FaissVS(), cs=SQLiteFTSStore())"
   ],
   "id": "78fb4d3bf0f58ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 17:28:58,410 - INFO - Load pretrained SentenceTransformer: clip-ViT-L-14\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T17:12:30.022751Z",
     "start_time": "2025-08-25T17:12:08.516967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.sem_index(\"image\", index_dir=f\"image_{sample_size_percentage}_index\")\n",
    "df = df.sem_index(\"productDisplayName\", index_dir=f\"productDisplayName_{sample_size_percentage}_index\")\n",
    "\n"
   ],
   "id": "95d55c274350948c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 17:12:08,518 - WARNING - Do not reset the dataframe index to ensure proper functionality of get_vectors_from_index\n",
      "2025-08-25 17:12:29,650 - WARNING - Do not reset the dataframe index to ensure proper functionality of get_vectors_from_index\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T17:31:07.370931Z",
     "start_time": "2025-08-25T17:31:07.341611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df = df.load_sem_index(\"image\", index_dir=f\"image_{sample_size_percentage}_index\")\n",
    "# df = df.load_sem_index(\"image_url\", index_dir=f\"image_{sample_size_percentage}_index\")\n",
    "# df = df.load_sem_index(\"productDisplayName\", index_dir=f\"productDisplayName_{sample_size_percentage}_index\")\n",
    "\n",
    "df = df.sem_captions_index.attach_index(\"image\", index_dir=DATASET_CAPTION_DB)\n",
    "df = df.sem_captions_index.load(\"image\")\n",
    "\n",
    "df_f = df.sem_captions_index.search(\"white man shirt\", \"image\", K=500)\n",
    "df_f = df_f.sem_captions_index.search(\"jeans\", \"image\", K=500)\n"
   ],
   "id": "4b4592cea0da91d5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full LLM calls",
   "id": "b3ed2f3f83212c79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T17:15:45.913259Z",
     "start_time": "2025-08-25T17:15:38.159326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# merged_df_filtered_white_tshirts = df.sem_filter(\"{_image} is a product of white T-shirt\", return_stats=False)\n",
    "# merged_df_filtered_socks = df.sem_filter(\"{_image} is a product of a sock\", return_stats=False)\n",
    "# merged_df_filtered_wallet = df.sem_filter(\"{_image} shows a wallet\", return_stats=False)\n",
    "merged_df_filtered_black_footwear = df.sem_filter(\"tshirt\", col_li=[\"image_url\"], return_stats=False)\n"
   ],
   "id": "ab5b4f2d578adba8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 50/50 LM calls [00:07<00:00,  6.46it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Binary search filter",
   "id": "f04a103061f9897b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T17:14:10.734268Z",
     "start_time": "2025-08-25T17:13:36.262998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "merged_df_filtered =  df.sem_filter(\"tshirt\", col_li=[\"image_url\"], cascade_args=cascade_args, return_stats=True, find_top_k=True)\n"
   ],
   "id": "b5f27a75d38cc16c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.78s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:03<00:00,  3.38s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:03<00:00,  3.66s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.31s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:08<00:00,  8.60s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:03<00:00,  3.54s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:06<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T17:18:17.789406Z",
     "start_time": "2025-08-25T17:18:17.781623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from join_optimizer.lotus.evaluate import evaluate_filter\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=merged_df_filtered_black_footwear,\n",
    "    filtered_df=merged_df_filtered,\n",
    "    article_type=None,\n",
    "    base_colour=None\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "5ba288ea49f13a18",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 11, 'FP': 1, 'FN': 1, 'precision': 0.9166666666666666, 'recall': 0.9166666666666666, 'f1': 0.9166666666666666}\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sampling",
   "id": "79fc675e90499e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "363c1ed6f3ac4873",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import importlib\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "importlib.reload(sys.modules['lotus.sem_ops.cascade_utils'])\n",
    "importlib.reload(sys.modules['lotus.sem_ops.sem_filter'])\n",
    "importlib.reload(sys.modules['lotus'])\n",
    "importlib.reload(sys.modules['pandas'])\n",
    "import lotus.sem_ops.sem_filter\n",
    "import lotus\n",
    "\n",
    "# Ensure you import the module (not just the function) so autoreload can update it:\n",
    "import lotus.sem_ops.sem_filter as sem_filter_mod\n"
   ],
   "id": "7cde71f0f9e0acbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.95,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    "    cascade_IS_weight=1,\n",
    "    cascade_num_calibration_quantiles = 100,\n",
    "    failure_probability=0.1,\n",
    "    cascade_IS_random_seed=114,\n",
    "    cascade_IS_max_sample_range=444\n",
    "\n",
    ")\n",
    "\n",
    "merged_df_filtered_big =  df.sem_filter(\"{_image} shows a wallet\", cascade_args=cascade_args ,return_stats=False, find_top_k=False)\n"
   ],
   "id": "82def2fdedfe44f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import *\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=merged_df_filtered_wallet,\n",
    "    filtered_df=merged_df_filtered_big,\n",
    "    article_type=None,\n",
    "    base_colour=None\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "95dd9b27d9c2da8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Just sim_search",
   "id": "c9245f4a3047d9c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sem_search with similarity scores returned\n",
    "sim_df_with_scores = df.sem_search(\n",
    "    \"productDisplayName\",\n",
    "    # \"You will receive an image of a product. Determine whether the product can be worn on the feet, like shoes, sandals, flip-flops, ... The predominant color of the depicted product should be black. If there are multiple products in the picture, always refer to the most promiment one.\",\n",
    "    \"black wallet\",\n",
    "    K=10,\n",
    "    return_scores=True,\n",
    "    suffix=\"_similarity_score\"\n",
    ")\n"
   ],
   "id": "418a238b5b0914f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Joins",
   "id": "405a29efc2db46a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res_sim_join = merged_df_filtered.sem_sim_join(df, left_on='_image', right_on='productDisplayName', K=1, keep_index=True)",
   "id": "648774f9d25b0e72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {_image}?\"\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.75,\n",
    "    sampling_percentage=0.04,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "res = merged_df_filtered.sem_join(df, expr,cascade_args=cascade_args, return_stats=True)\n",
    "\n",
    "# print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n"
   ],
   "id": "f9d77a583c15e828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = 0",
   "id": "4635aa11d0ed6e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "expr = \"given {productDisplayName}, which {_image} does more exactly and precisely match?\"\n",
    "\n",
    "ranked, stats = res[0].sem_topk(\n",
    "    expr,\n",
    "    K=1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked\n"
   ],
   "id": "1e3d8b09b9168f1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "join_topk = ranked.query('_id == id')\n",
    "sim_1 = res_sim_join.query('_id == id')"
   ],
   "id": "183eb16c180b142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7d3292e4509f3b48",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
