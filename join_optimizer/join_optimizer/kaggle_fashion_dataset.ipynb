{
 "cells": [
  {
   "cell_type": "code",
   "id": "d1766453fee4269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T22:35:43.819331Z",
     "start_time": "2025-07-22T22:35:43.783244Z"
    }
   },
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "from lotus.dtype_extensions import ImageArray\n",
    "\n",
    "parquet_path_sampeled = 'fashion_product_images_001/styles.parquet'\n",
    "parquet_path = 'fashion_product_images_001/styles.parquet'\n",
    "details_path = 'fashion_product_images_001/styles_details.parquet'\n",
    "sample_size = 0.001\n",
    "df = duckdb.query(f\"\"\"\n",
    "with images as (\n",
    "    SELECT *\n",
    "    FROM parquet_scan('{parquet_path}')\n",
    "    -- USING SAMPLE {sample_size * 100} PERCENT (reservoir, 80)\n",
    "    )\n",
    "    select\n",
    "     images.id ,images.subcategory, images.articletype, images.basecolour, details.price, images.productDisplayName, styleimages.default.imageURL\n",
    "    -- *\n",
    "    from images, parquet_scan('{details_path}') details\n",
    "    where images.id = details.id\n",
    "    -- and details.price <1000\n",
    "    limit 50\n",
    "\n",
    "\"\"\").to_df()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "75be5e20a353d22",
   "metadata": {},
   "source": [
    "image_file_names = df[\"id\"]\n",
    "image_URLs = df[\"imageURL\"]\n",
    "image_paths = [os.path.join(\"fashion_product_images/images_resized\", str(image) + \".jpg\") for image in image_file_names]\n",
    "df2 = pd.DataFrame({\"image\": ImageArray(image_URLs), \"label\": image_file_names, \"image_path\": image_paths, \"image_URLs\": image_URLs , \"articleType\": df[\"articleType\"], \"baseColour\": df[\"baseColour\"]})\n",
    "merged_df = pd.merge(df, df2,  left_on='id', right_on='label')\n",
    "merged_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0046b9abcc176f6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "from lotus.types import CascadeArgs\n",
    "from lotus.vector_store import FaissVS\n",
    "lm = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm, rm=rm, vs=vs)\n",
    "\n",
    "lm.print_total_usage()\n",
    "\n",
    "filtered_df2 = (df2\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9340560bc76edd8",
   "metadata": {},
   "source": [
    "image_paths_big = [os.path.join(\"fashion_product_images/images\", str(image) + \".jpg\") for image in image_file_names if str(image)[10] == 1]\n",
    "df2_big = pd.DataFrame({\"image\": ImageArray(image_paths_big), \"label\": image_file_names, \"image_path\": image_paths})\n",
    "\n",
    "lm_2 = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm_2, rm=rm, vs=vs)\n",
    "\n",
    "lm_2.print_total_usage()\n",
    "\n",
    "filtered_df2_big = (df2_big\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm_2.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b944ef366075f84a",
   "metadata": {},
   "source": [
    "filtered_df2\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d233b25ca737b626",
   "metadata": {},
   "source": [
    "filtered_df = (df\n",
    "                .sem_filter(\"The {articleType}, {baseColour} and {productDisplayName} might show a t-shirt that might be white\")\n",
    "                )\n",
    "lm.print_total_usage()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a72c46228dbec3c",
   "metadata": {},
   "source": [
    "filtered_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0979d8eafc0af6d",
   "metadata": {},
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {image}?\"\n",
    "\n",
    "\n",
    "cascade_args = CascadeArgs(recall_target=0.8, precision_target=0.8)\n",
    "res = filtered_df.sem_join(filtered_df2, expr, return_stats=True, strategy=\"zs-cot\")\n",
    "\n",
    "\n",
    "print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n",
    "res"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "835f646083e2f020",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8592115d4532007f",
   "metadata": {},
   "source": [
    "expr = \"given {productDisplayName}, which {image} does more exactly and precisely match?\"\n",
    "\n",
    "\n",
    "ranked, stats = res.sem_topk(\n",
    "    expr,\n",
    "    K = 1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fe4e358ef6ee786",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e760e63f124f19b8",
   "metadata": {},
   "source": [
    "# Independent\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lotus.vector_store import FaissVS\n",
    "from lotus.models import SentenceTransformersRM\n",
    "import lotus\n",
    "\n",
    "# CLIP embedding model â€“ works for both text & image\n",
    "# rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "\n",
    "lotus.settings.configure(rm=rm, vs=FaissVS())\n",
    "\n",
    "merged_df = merged_df.sem_index(\"image\", index_dir=\"image_index\")\n"
   ],
   "id": "95d55c274350948c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cands = merged_df.sem_search(\"image\", \"watch\", K=5, return_scores=True)\n",
   "id": "419bc29232689c71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cands",
   "id": "9e09f627b300f90d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
