{
 "cells": [
  {
   "cell_type": "code",
   "id": "d1766453fee4269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:23:11.229868Z",
     "start_time": "2025-08-08T14:23:11.143976Z"
    }
   },
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "from lotus.dtype_extensions import ImageArray\n",
    "\n",
    "parquet_path_sampeled = 'fashion_product_images_001/styles.parquet'\n",
    "parquet_path = 'fashion_product_images_001/styles.parquet'\n",
    "details_path = 'fashion_product_images_001/styles_details.parquet'\n",
    "sample_size = 0.3\n",
    "df = duckdb.query(f\"\"\"\n",
    "with images as (\n",
    "    SELECT *\n",
    "    FROM parquet_scan('{parquet_path}')\n",
    "    USING SAMPLE {sample_size * 100} PERCENT (reservoir, 80)\n",
    "    )\n",
    "    select\n",
    "     images.id ,images.subcategory, images.articletype, images.basecolour, details.price, images.productDisplayName, styleimages.default.imageURL\n",
    "    -- *\n",
    "    from images, parquet_scan('{details_path}') details\n",
    "    where images.id = details.id\n",
    "    -- and details.price <1000\n",
    "\n",
    "\"\"\").to_df()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "75be5e20a353d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:23:14.599670Z",
     "start_time": "2025-08-08T14:23:14.588866Z"
    }
   },
   "source": [
    "image_file_names = df[\"id\"]\n",
    "image_URLs = df[\"imageURL\"]\n",
    "image_paths = [os.path.join(\"fashion_product_images/images_resized\", str(image) + \".jpg\") for image in image_file_names]\n",
    "df2 = pd.DataFrame({\"image\": ImageArray(image_URLs), \"label\": image_file_names, \"image_path\": image_paths, \"image_URLs\": image_URLs , \"articleType\": df[\"articleType\"], \"baseColour\": df[\"baseColour\"]})\n",
    "merged_df = pd.merge(df, df2,  left_on='id', right_on='label')\n",
    "merged_df.columns = ['_' + col for col in merged_df.columns]\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.p\n",
   "id": "6e25eef48224bc6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0046b9abcc176f6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "from lotus.types import CascadeArgs\n",
    "from lotus.vector_store import FaissVS\n",
    "lm = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm, rm=rm, vs=vs)\n",
    "\n",
    "lm.print_total_usage()\n",
    "\n",
    "filtered_df2 = (df2\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9340560bc76edd8",
   "metadata": {},
   "source": [
    "image_paths_big = [os.path.join(\"fashion_product_images/images\", str(image) + \".jpg\") for image in image_file_names if str(image)[10] == 1]\n",
    "df2_big = pd.DataFrame({\"image\": ImageArray(image_paths_big), \"label\": image_file_names, \"image_path\": image_paths})\n",
    "\n",
    "lm_2 = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm_2, rm=rm, vs=vs)\n",
    "\n",
    "lm_2.print_total_usage()\n",
    "\n",
    "filtered_df2_big = (df2_big\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm_2.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b944ef366075f84a",
   "metadata": {},
   "source": [
    "filtered_df2\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d233b25ca737b626",
   "metadata": {},
   "source": [
    "filtered_df = (df\n",
    "                .sem_filter(\"The {articleType}, {baseColour} and {productDisplayName} might show a t-shirt that might be white\")\n",
    "                )\n",
    "lm.print_total_usage()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a72c46228dbec3c",
   "metadata": {},
   "source": [
    "filtered_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0979d8eafc0af6d",
   "metadata": {},
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {image}?\"\n",
    "\n",
    "\n",
    "cascade_args = CascadeArgs(recall_target=0.8, precision_target=0.8)\n",
    "res = filtered_df.sem_join(filtered_df2, expr, return_stats=True, strategy=\"zs-cot\")\n",
    "\n",
    "\n",
    "print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n",
    "res"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "835f646083e2f020",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8592115d4532007f",
   "metadata": {},
   "source": [
    "expr = \"given {productDisplayName}, which {image} does more exactly and precisely match?\"\n",
    "\n",
    "\n",
    "ranked, stats = res.sem_topk(\n",
    "    expr,\n",
    "    K = 1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fe4e358ef6ee786",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e760e63f124f19b8",
   "metadata": {},
   "source": "# SEM INDEX\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating the index",
   "id": "fa1051743c8b80ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:33:58.876205Z",
     "start_time": "2025-08-08T14:31:33.095640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lotus.vector_store import FaissVS\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "\n",
    "gpt_4o_mini = LM(\"gpt-4o-mini\")\n",
    "gpt_4o = LM(\"gpt-4o\")\n",
    "\n",
    "# CLIP embedding model – works for both text & image\n",
    "# rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "rm  = SentenceTransformersRM(model=\"clip-ViT-L-14\", max_batch_size=32)\n",
    "\n",
    "lotus.settings.configure(lm=gpt_4o, helper_lm=gpt_4o_mini, rm=rm, vs=FaissVS())\n",
    "\n",
    "merged_df = merged_df.sem_index(\"_image\", index_dir=\"image_index\")\n",
    "df = df.sem_index(\"productDisplayName\", index_dir=\"productDisplayName_index\")\n",
    "\n"
   ],
   "id": "95d55c274350948c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 14:31:33,100 - INFO - Use pytorch device_name: cpu\n",
      "2025-08-08 14:31:33,102 - INFO - Load pretrained SentenceTransformer: clip-ViT-L-14\n",
      "2025-08-08 14:31:34,553 - WARNING - Do not reset the dataframe index to ensure proper functionality of get_vectors_from_index\n",
      "2025-08-08 14:33:56,496 - WARNING - Do not reset the dataframe index to ensure proper functionality of get_vectors_from_index\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Binary search filter",
   "id": "1d764ac7ecc66e0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T14:38:03.336801Z",
     "start_time": "2025-08-08T14:36:47.948366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.75,\n",
    "    sampling_percentage=0.3,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "merged_df_filtered =  merged_df.sem_filter(\"{_image} is a watch\",cascade_args=cascade_args, return_stats=True, find_top_k=True)\n",
    "\n",
    "\n"
   ],
   "id": "b5f27a75d38cc16c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|██████████ 1/1 LM calls [00:02<00:00,  2.60s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:02<00:00,  2.32s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.96s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:02<00:00,  2.74s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:05<00:00,  5.37s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:03<00:00,  3.11s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:04<00:00,  4.67s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:01<00:00,  1.74s/it]\n",
      "Filtering: 100%|██████████ 1/1 LM calls [00:06<00:00,  6.40s/it]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T12:03:01.706004Z",
     "start_time": "2025-08-02T12:03:01.694952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import *\n",
    "\n",
    "metrics = evaluate_filter(\n",
    "    merged_df=merged_df,\n",
    "    filtered_df=merged_df_filtered,\n",
    "    article_type='Tshirts',\n",
    "    base_colour='White'\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "5ba288ea49f13a18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 12, 'FP': 3, 'FN': 2, 'precision': 0.8, 'recall': 0.8571428571428571, 'f1': 0.8275862068965518}\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### full LLM calls",
   "id": "79fc675e90499e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T15:43:58.432451Z",
     "start_time": "2025-08-09T15:43:32.910682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.75,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "merged_df_filtered_big =  merged_df.sem_filter(\"{_image} is a watch\", cascade_args=cascade_args ,return_stats=False, find_top_k=False)\n"
   ],
   "id": "82def2fdedfe44f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running oracle for threshold learning: 100%|██████████ 13/13 LM calls [00:09<00:00,  1.32it/s]\n",
      "2025-08-09 15:43:47,071 - INFO - Sample recall: 1.0\n",
      "2025-08-09 15:43:47,073 - INFO - Sample precision: 1.0\n",
      "2025-08-09 15:43:47,074 - INFO - Learned cascade thresholds: (1.0, 0.1390555500984192)\n",
      "2025-08-09 15:43:47,075 - INFO - Num routed to smaller model: 45\n",
      "Running predicate evals with oracle LM: 100%|██████████ 88/88 LM calls [00:11<00:00,  7.99it/s]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T12:03:01.638304Z",
     "start_time": "2025-08-02T12:03:01.624728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = evaluate_filter(\n",
    "    merged_df=merged_df,\n",
    "    filtered_df=merged_df_filtered_big,\n",
    "    article_type='Tshirts',\n",
    "    base_colour='White'\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "95dd9b27d9c2da8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 8, 'FP': 1, 'FN': 6, 'precision': 0.8888888888888888, 'recall': 0.5714285714285714, 'f1': 0.6956521739130435}\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Joins",
   "id": "405a29efc2db46a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T18:55:12.670046Z",
     "start_time": "2025-08-02T18:55:12.649213Z"
    }
   },
   "cell_type": "code",
   "source": "res_sim_join = merged_df_filtered.sem_sim_join(df, left_on='_image', right_on='productDisplayName', K=1, keep_index=True)",
   "id": "648774f9d25b0e72",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:41:32.603130Z",
     "start_time": "2025-08-08T13:41:15.458688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {_image}?\"\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.75,\n",
    "    sampling_percentage=0.04,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "res = merged_df_filtered.sem_join(df, expr,cascade_args=cascade_args, return_stats=True)\n",
    "\n",
    "# print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n"
   ],
   "id": "f9d77a583c15e828",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhia/miniconda3/envs/lotus/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/dhia/miniconda3/envs/lotus/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'merged_df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlotus\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CascadeArgs, ProxyModel\n\u001B[32m      4\u001B[39m cascade_args = CascadeArgs(\n\u001B[32m      5\u001B[39m     recall_target=\u001B[32m0.9\u001B[39m,\n\u001B[32m      6\u001B[39m     precision_target=\u001B[32m0.75\u001B[39m,\n\u001B[32m      7\u001B[39m     sampling_percentage=\u001B[32m0.04\u001B[39m,\n\u001B[32m      8\u001B[39m     proxy_model=ProxyModel.EMBEDDING_MODEL,\n\u001B[32m      9\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m res = merged_df_filtered.sem_join(df, expr,cascade_args=cascade_args, return_stats=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mNameError\u001B[39m: name 'merged_df_filtered' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = 0",
   "id": "4635aa11d0ed6e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "expr = \"given {productDisplayName}, which {_image} does more exactly and precisely match?\"\n",
    "\n",
    "ranked, stats = res[0].sem_topk(\n",
    "    expr,\n",
    "    K=1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked\n"
   ],
   "id": "1e3d8b09b9168f1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T18:12:27.544005Z",
     "start_time": "2025-08-03T18:12:27.523089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "join_topk = ranked.query('_id == id')\n",
    "sim_1 = res_sim_join.query('_id == id')"
   ],
   "id": "183eb16c180b142",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d3292e4509f3b48"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
