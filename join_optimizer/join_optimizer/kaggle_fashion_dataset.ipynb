{
 "cells": [
  {
   "cell_type": "code",
   "id": "d1766453fee4269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:32:52.444213Z",
     "start_time": "2025-08-13T15:32:38.679984Z"
    }
   },
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "from lotus.dtype_extensions import ImageArray\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "import pandas as pd\n",
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import *\n",
    "\n",
    "\n",
    "parquet_path_sampeled = 'fashion_product_images_001/styles.parquet'\n",
    "parquet_path = 'fashion_product_images_001/styles.parquet'\n",
    "details_path = 'fashion_product_images_001/styles_details.parquet'\n",
    "sample_size = 1\n",
    "df = duckdb.query(f\"\"\"\n",
    "with images as (\n",
    "    SELECT *\n",
    "    FROM parquet_scan('{parquet_path}')\n",
    "    USING SAMPLE {sample_size * 100} PERCENT (reservoir, 80)\n",
    "    )\n",
    "    select\n",
    "     images.id ,images.subcategory, images.articletype, images.basecolour, details.price, images.productDisplayName, styleimages.default.imageURL\n",
    "    -- *\n",
    "    from images, parquet_scan('{details_path}') details\n",
    "    where images.id = details.id\n",
    "    -- and details.price <1000\n",
    "\n",
    "\"\"\").to_df()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhia/miniconda3/envs/lotus/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/dhia/miniconda3/envs/lotus/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "75be5e20a353d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:32:52.469954Z",
     "start_time": "2025-08-13T15:32:52.457935Z"
    }
   },
   "source": [
    "image_file_names = df[\"id\"]\n",
    "image_URLs = df[\"imageURL\"]\n",
    "image_paths = [os.path.join(\"fashion_product_images/images_resized\", str(image) + \".jpg\") for image in image_file_names]\n",
    "df2 = pd.DataFrame({\"image\": ImageArray(image_URLs), \"label\": image_file_names, \"image_path\": image_paths, \"image_URLs\": image_URLs , \"articleType\": df[\"articleType\"], \"baseColour\": df[\"baseColour\"]})\n",
    "merged_df = pd.merge(df, df2,  left_on='id', right_on='label')\n",
    "merged_df.columns = ['_' + col for col in merged_df.columns]\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.p\n",
   "id": "6e25eef48224bc6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0046b9abcc176f6",
   "metadata": {},
   "source": [
    "\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "from lotus.types import CascadeArgs\n",
    "from lotus.vector_store import FaissVS\n",
    "lm = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm, rm=rm, vs=vs)\n",
    "\n",
    "lm.print_total_usage()\n",
    "\n",
    "filtered_df2 = (df2\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9340560bc76edd8",
   "metadata": {},
   "source": [
    "image_paths_big = [os.path.join(\"fashion_product_images/images\", str(image) + \".jpg\") for image in image_file_names if str(image)[10] == 1]\n",
    "df2_big = pd.DataFrame({\"image\": ImageArray(image_paths_big), \"label\": image_file_names, \"image_path\": image_paths})\n",
    "\n",
    "lm_2 = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm_2, rm=rm, vs=vs)\n",
    "\n",
    "lm_2.print_total_usage()\n",
    "\n",
    "filtered_df2_big = (df2_big\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm_2.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b944ef366075f84a",
   "metadata": {},
   "source": [
    "filtered_df2\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d233b25ca737b626",
   "metadata": {},
   "source": [
    "filtered_df = (df\n",
    "                .sem_filter(\"The {articleType}, {baseColour} and {productDisplayName} might show a t-shirt that might be white\")\n",
    "                )\n",
    "lm.print_total_usage()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a72c46228dbec3c",
   "metadata": {},
   "source": [
    "filtered_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0979d8eafc0af6d",
   "metadata": {},
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {image}?\"\n",
    "\n",
    "\n",
    "cascade_args = CascadeArgs(recall_target=0.8, precision_target=0.8)\n",
    "res = filtered_df.sem_join(filtered_df2, expr, return_stats=True, strategy=\"zs-cot\")\n",
    "\n",
    "\n",
    "print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n",
    "res"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "835f646083e2f020",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8592115d4532007f",
   "metadata": {},
   "source": [
    "expr = \"given {productDisplayName}, which {image} does more exactly and precisely match?\"\n",
    "\n",
    "\n",
    "ranked, stats = res.sem_topk(\n",
    "    expr,\n",
    "    K = 1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fe4e358ef6ee786",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e760e63f124f19b8",
   "metadata": {},
   "source": "# SEM INDEX\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating the index",
   "id": "fa1051743c8b80ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:32:53.900021Z",
     "start_time": "2025-08-13T15:32:52.518615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lotus.vector_store import FaissVS\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "\n",
    "gpt_4o_mini = LM(\"gpt-4o-mini\")\n",
    "gpt_4o = LM(\"gpt-4o\")\n",
    "\n",
    "# CLIP embedding model â€“ works for both text & image\n",
    "# rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "rm  = SentenceTransformersRM(model=\"clip-ViT-L-14\", max_batch_size=32)\n",
    "\n",
    "lotus.settings.configure(lm=gpt_4o, helper_lm=gpt_4o_mini, rm=rm, vs=FaissVS())"
   ],
   "id": "78fb4d3bf0f58ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 15:32:52,524 - INFO - Use pytorch device_name: cpu\n",
      "2025-08-13 15:32:52,526 - INFO - Load pretrained SentenceTransformer: clip-ViT-L-14\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:40:48.018501Z",
     "start_time": "2025-08-13T15:32:54.004105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_df = merged_df.sem_index(\"_image\", index_dir=\"image_100_index\")\n",
    "df = df.sem_index(\"productDisplayName\", index_dir=\"productDisplayName_100_index\")\n",
    "\n"
   ],
   "id": "95d55c274350948c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 15:32:54,006 - WARNING - Do not reset the dataframe index to ensure proper functionality of get_vectors_from_index\n",
      "2025-08-13 15:40:40,989 - WARNING - Do not reset the dataframe index to ensure proper functionality of get_vectors_from_index\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:40:48.104543Z",
     "start_time": "2025-08-13T15:40:48.100011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_df = merged_df.load_sem_index(\"_image\", index_dir=\"image_100_index\")\n",
    "df = df.load_sem_index(\"productDisplayName\", index_dir=\"productDisplayName_100_index\")\n",
    "# merged_df = merged_df.sem_map(\"Describe the product in the {_image} in 15 words.\", suffix = \"_description\")\n"
   ],
   "id": "4b4592cea0da91d5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Full LLM calls",
   "id": "b3ed2f3f83212c79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:48:44.543848Z",
     "start_time": "2025-08-13T15:45:31.331473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# merged_df_filtered_white_tshirts = merged_df.sem_filter(\"{_image} is a product of white T-shirt\", return_stats=False)\n",
    "# merged_df_filtered_socks = merged_df.sem_filter(\"{_image} is a product of a sock\", return_stats=False)\n",
    "# merged_df_filtered_wallet = merged_df.sem_filter(\"{_image} shows a wallet\", return_stats=False)\n",
    "merged_df_filtered_black_footwear = merged_df.sem_filter(\"You will receive an {_image} of a product. Determine whether the product can be worn on the feet, like shoes, sandals, flip-flops, ... The predominant color of the depicted product should be black. If there are multiple products in the picture, always refer to the most prominent one.\", return_stats=False)\n"
   ],
   "id": "ab5b4f2d578adba8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering:   0%|           0/444 LM calls [00:00<?, ?it/s]2025-08-13 15:48:07,917 - INFO - Retrying request to /chat/completions in 0.430146 seconds\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 444/444 LM calls [00:40<00:00, 10.87it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Binary search filter",
   "id": "f04a103061f9897b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:53:08.554910Z",
     "start_time": "2025-08-13T15:49:23.062117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "merged_df_filtered =  merged_df.sem_filter(\"{_image} shows a white tshirt\",cascade_args=cascade_args, return_stats=True, find_top_k=True)"
   ],
   "id": "b5f27a75d38cc16c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:08<00:00,  8.22s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:01<00:00,  1.95s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:03<00:00,  3.27s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:02<00:00,  2.43s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:08<00:00,  8.76s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:04<00:00,  4.43s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:10<00:00, 10.81s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:10<00:00, 10.16s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:04<00:00,  4.58s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:01<00:00,  1.91s/it]\n",
      "Filtering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 1/1 LM calls [00:03<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T11:02:58.755520Z",
     "start_time": "2025-08-12T11:02:58.746961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import *\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=merged_df_filtered_wallet,\n",
    "    filtered_df=merged_df_filtered,\n",
    "    article_type=None,\n",
    "    base_colour=None\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "5ba288ea49f13a18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 5, 'FP': 1, 'FN': 3, 'precision': 0.8333333333333334, 'recall': 0.625, 'f1': 0.7142857142857143}\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sampling",
   "id": "79fc675e90499e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "importlib.reload(sys.modules['lotus.sem_ops.cascade_utils'])\n",
    "importlib.reload(sys.modules['lotus.sem_ops.sem_filter'])\n",
    "importlib.reload(sys.modules['join_optimizer.join_optimizer.productDisplayName_index.evaluate'])"
   ],
   "id": "7cde71f0f9e0acbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T10:52:16.901882Z",
     "start_time": "2025-08-12T10:51:16.560003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.95,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    "    cascade_IS_weight=1,\n",
    "    cascade_num_calibration_quantiles = 100,\n",
    "    failure_probability=0.1,\n",
    "    cascade_IS_random_seed=114,\n",
    "    cascade_IS_max_sample_range=444\n",
    "\n",
    ")\n",
    "\n",
    "merged_df_filtered_big =  merged_df.sem_filter(\"{_image} shows a wallet\", cascade_args=cascade_args ,return_stats=False, find_top_k=False)\n"
   ],
   "id": "82def2fdedfe44f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running oracle for threshold learning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 44/44 LM calls [00:10<00:00,  4.26it/s]\n",
      "2025-08-12 10:51:40,123 - INFO - Sample recall: 1.0\n",
      "2025-08-12 10:51:40,126 - INFO - Sample precision: 1.0\n",
      "2025-08-12 10:51:40,128 - INFO - Learned cascade thresholds: (0.22658105194568634, 0.11210895329713821)\n",
      "2025-08-12 10:51:40,132 - INFO - Num routed to smaller model: 12\n",
      "Running predicate evals with oracle LM: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 432/432 LM calls [00:35<00:00, 12.32it/s]\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T10:52:20.943209Z",
     "start_time": "2025-08-12T10:52:20.932602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import *\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=merged_df_filtered_wallet,\n",
    "    filtered_df=merged_df_filtered_big,\n",
    "    article_type=None,\n",
    "    base_colour=None\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "95dd9b27d9c2da8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 8, 'FP': 1, 'FN': 0, 'precision': 0.8888888888888888, 'recall': 1.0, 'f1': 0.9411764705882353}\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Just sim_search",
   "id": "c9245f4a3047d9c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T15:42:23.050814Z",
     "start_time": "2025-08-13T15:42:22.860660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sem_search with similarity scores returned\n",
    "sim_df_with_scores = merged_df.sem_search(\n",
    "    \"_image\",\n",
    "    \"You will receive an image of a product. Determine whether the product can be worn on the feet, like shoes, sandals, flip-flops, ... The predominant color of the depicted product should be black. If there are multiple products in the picture, always refer to the most promiment one.\",\n",
    "    K=25,\n",
    "    return_scores=True,\n",
    "    suffix=\"_similarity_score\"  # This will create a column named \"vec_scores_similarity_score\"\n",
    ")\n"
   ],
   "id": "418a238b5b0914f1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Joins",
   "id": "405a29efc2db46a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:10:42.654758Z",
     "start_time": "2025-08-10T21:10:42.033072Z"
    }
   },
   "cell_type": "code",
   "source": "res_sim_join = merged_df_filtered.sem_sim_join(df, left_on='_image', right_on='productDisplayName', K=1, keep_index=True)",
   "id": "648774f9d25b0e72",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m res_sim_join = merged_df_filtered.sem_sim_join(df, left_on=\u001B[33m'\u001B[39m\u001B[33m_image\u001B[39m\u001B[33m'\u001B[39m, right_on=\u001B[33m'\u001B[39m\u001B[33mproductDisplayName\u001B[39m\u001B[33m'\u001B[39m, K=\u001B[32m1\u001B[39m, keep_index=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mNameError\u001B[39m: name 'merged_df_filtered' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:41:32.603130Z",
     "start_time": "2025-08-08T13:41:15.458688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {_image}?\"\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.75,\n",
    "    sampling_percentage=0.04,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "res = merged_df_filtered.sem_join(df, expr,cascade_args=cascade_args, return_stats=True)\n",
    "\n",
    "# print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n"
   ],
   "id": "f9d77a583c15e828",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhia/miniconda3/envs/lotus/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/dhia/miniconda3/envs/lotus/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'merged_df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlotus\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CascadeArgs, ProxyModel\n\u001B[32m      4\u001B[39m cascade_args = CascadeArgs(\n\u001B[32m      5\u001B[39m     recall_target=\u001B[32m0.9\u001B[39m,\n\u001B[32m      6\u001B[39m     precision_target=\u001B[32m0.75\u001B[39m,\n\u001B[32m      7\u001B[39m     sampling_percentage=\u001B[32m0.04\u001B[39m,\n\u001B[32m      8\u001B[39m     proxy_model=ProxyModel.EMBEDDING_MODEL,\n\u001B[32m      9\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m res = merged_df_filtered.sem_join(df, expr,cascade_args=cascade_args, return_stats=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mNameError\u001B[39m: name 'merged_df_filtered' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = 0",
   "id": "4635aa11d0ed6e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "expr = \"given {productDisplayName}, which {_image} does more exactly and precisely match?\"\n",
    "\n",
    "ranked, stats = res[0].sem_topk(\n",
    "    expr,\n",
    "    K=1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked\n"
   ],
   "id": "1e3d8b09b9168f1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T18:12:27.544005Z",
     "start_time": "2025-08-03T18:12:27.523089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "join_topk = ranked.query('_id == id')\n",
    "sim_1 = res_sim_join.query('_id == id')"
   ],
   "id": "183eb16c180b142",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d3292e4509f3b48"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
