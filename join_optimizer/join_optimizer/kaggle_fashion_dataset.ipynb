{
 "cells": [
  {
   "cell_type": "code",
   "id": "d1766453fee4269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:11:45.980931Z",
     "start_time": "2025-08-15T16:11:35.974628Z"
    }
   },
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "from lotus.dtype_extensions import ImageArray\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "import pandas as pd\n",
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import evaluate_filter\n",
    "\n",
    "\n",
    "parquet_path_sampeled = 'fashion_product_images/styles.parquet'\n",
    "parquet_path = 'fashion_product_images/styles.parquet'\n",
    "details_path = 'fashion_product_images/styles_details.parquet'\n",
    "sample_size = 0.02\n",
    "df = duckdb.query(f\"\"\"\n",
    "with images as (\n",
    "    SELECT *\n",
    "    FROM parquet_scan('{parquet_path}')\n",
    "    USING SAMPLE {sample_size * 100} PERCENT (reservoir, 80)\n",
    "    )\n",
    "    select\n",
    "     images.id ,images.subcategory, images.articletype, images.basecolour, details.price, images.productDisplayName,\n",
    "     -- styleimages.default.resolutions.\"360X480\"  as imageURL\n",
    "     styleimages.default.imageURL  as imageURL\n",
    "    -- *\n",
    "    from images, parquet_scan('{details_path}') details\n",
    "    where images.id = details.id\n",
    "    -- and details.price <1000\n",
    "    order by images.id\n",
    "\"\"\").to_df()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/halle/bouassid/home_at/miniconda3/envs/lotus/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "75be5e20a353d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:11:45.995624Z",
     "start_time": "2025-08-15T16:11:45.987230Z"
    }
   },
   "source": [
    "image_file_names = df[\"id\"]\n",
    "image_URLs = df[\"imageURL\"]\n",
    "image_paths = [os.path.join(\"fashion_product_images/images_resized\", str(image) + \".jpg\") for image in image_file_names]\n",
    "df2 = pd.DataFrame({\"image\": ImageArray(image_URLs), \"label\": image_file_names, \"image_path\": image_paths, \"image_URLs\": image_URLs , \"articleType\": df[\"articleType\"], \"baseColour\": df[\"baseColour\"]})\n",
    "merged_df = pd.merge(df, df2,  left_on='id', right_on='label')\n",
    "merged_df.columns = ['_' + col for col in merged_df.columns]\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x.p\n",
   "id": "6e25eef48224bc6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0046b9abcc176f6",
   "metadata": {},
   "source": [
    "\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "from lotus.types import CascadeArgs\n",
    "from lotus.vector_store import FaissVS\n",
    "lm = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm, rm=rm, vs=vs)\n",
    "\n",
    "lm.print_total_usage()\n",
    "\n",
    "filtered_df2 = (df2\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9340560bc76edd8",
   "metadata": {},
   "source": [
    "image_paths_big = [os.path.join(\"fashion_product_images/images\", str(image) + \".jpg\") for image in image_file_names if str(image)[10] == 1]\n",
    "df2_big = pd.DataFrame({\"image\": ImageArray(image_paths_big), \"label\": image_file_names, \"image_path\": image_paths})\n",
    "\n",
    "lm_2 = LM(model=\"gemini/gemini-2.0-flash-lite\")\n",
    "rm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n",
    "vs = FaissVS()\n",
    "lotus.settings.configure(lm=lm_2, rm=rm, vs=vs)\n",
    "\n",
    "lm_2.print_total_usage()\n",
    "\n",
    "filtered_df2_big = (df2_big\n",
    "                .sem_filter(\"the content  of {image} shows a white t-shirt\")\n",
    "                )\n",
    "lm_2.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b944ef366075f84a",
   "metadata": {},
   "source": [
    "filtered_df2\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d233b25ca737b626",
   "metadata": {},
   "source": [
    "filtered_df = (df\n",
    "                .sem_filter(\"The {articleType}, {baseColour} and {productDisplayName} might show a t-shirt that might be white\")\n",
    "                )\n",
    "lm.print_total_usage()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a72c46228dbec3c",
   "metadata": {},
   "source": [
    "filtered_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0979d8eafc0af6d",
   "metadata": {},
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {image}?\"\n",
    "\n",
    "\n",
    "cascade_args = CascadeArgs(recall_target=0.8, precision_target=0.8)\n",
    "res = filtered_df.sem_join(filtered_df2, expr, return_stats=True, strategy=\"zs-cot\")\n",
    "\n",
    "\n",
    "print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n",
    "res"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "835f646083e2f020",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8592115d4532007f",
   "metadata": {},
   "source": [
    "expr = \"given {productDisplayName}, which {image} does more exactly and precisely match?\"\n",
    "\n",
    "\n",
    "ranked, stats = res.sem_topk(\n",
    "    expr,\n",
    "    K = 1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fe4e358ef6ee786",
   "metadata": {},
   "source": [
    "lm.print_total_usage()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e760e63f124f19b8",
   "metadata": {},
   "source": "# SEM INDEX\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating the index",
   "id": "fa1051743c8b80ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:11:52.291381Z",
     "start_time": "2025-08-15T16:11:50.946983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lotus.vector_store import FaissVS\n",
    "import lotus\n",
    "from lotus.models import LM, SentenceTransformersRM\n",
    "\n",
    "gpt_4o_mini = LM(\"gpt-4o-mini\")\n",
    "gpt_4o = LM(\"gpt-4o\")\n",
    "\n",
    "# CLIP embedding model – works for both text & image\n",
    "# rm  = SentenceTransformersRM(model=\"clip-ViT-B-32\")\n",
    "rm  = SentenceTransformersRM(model=\"clip-ViT-L-14\", max_batch_size=32)\n",
    "\n",
    "lotus.settings.configure(lm=gpt_4o, helper_lm=gpt_4o_mini, rm=rm, vs=FaissVS())"
   ],
   "id": "78fb4d3bf0f58ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 18:11:50,967 - INFO - Use pytorch device_name: cpu\n",
      "2025-08-15 18:11:50,968 - INFO - Load pretrained SentenceTransformer: clip-ViT-L-14\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged_df = merged_df.sem_index(\"_image\", index_dir=f\"image_{sample_size}_index\")\n",
    "df = df.sem_index(\"productDisplayName\", index_dir=f\"productDisplayName_{sample_size}_index\")\n",
    "\n"
   ],
   "id": "95d55c274350948c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:11:54.265677Z",
     "start_time": "2025-08-15T16:11:54.260988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_df = merged_df.load_sem_index(\"_image\", index_dir=f\"image_{sample_size}_index\")\n",
    "merged_df = merged_df.load_sem_index(\"_imageURL\", index_dir=f\"image_{sample_size}_index\")\n",
    "df = df.load_sem_index(\"productDisplayName\", index_dir=f\"productDisplayName_{sample_size}_index\")\n",
    "# merged_df = merged_df.sem_map(\"extract the url from {_default} of an image resolution that is not sooo big but still okay for an llm to recognize the details. 360X480 or the one just bigger.\", suffix = \"_imageURL\")\n"
   ],
   "id": "4b4592cea0da91d5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Full LLM calls",
   "id": "b3ed2f3f83212c79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:12:21.544075Z",
     "start_time": "2025-08-15T16:12:10.770786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# merged_df_filtered_white_tshirts = merged_df.sem_filter(\"{_image} is a product of white T-shirt\", return_stats=False)\n",
    "# merged_df_filtered_socks = merged_df.sem_filter(\"{_image} is a product of a sock\", return_stats=False)\n",
    "# merged_df_filtered_wallet = merged_df.sem_filter(\"{_image} shows a wallet\", return_stats=False)\n",
    "merged_df_filtered_black_footwear = merged_df.sem_filter(\"You will receive an {_productDisplayName} of a product. Determine whether the product can be worn on the feet, like shoes, sandals, flip-flops, ... The predominant color of the depicted product should be black. If there are multiple products in the picture, always refer to the most prominent one.\", return_stats=False)\n"
   ],
   "id": "ab5b4f2d578adba8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering:   0%|           0/888 LM calls [00:00<?, ?it/s]2025-08-15 18:12:12,066 - INFO - Retrying request to /chat/completions in 0.485447 seconds\n",
      "Filtering: 100%|██████████ 888/888 LM calls [00:10<00:00, 83.04it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Binary search filter",
   "id": "f04a103061f9897b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "merged_df_filtered =  merged_df.sem_filter(\"the main product in the {_image} is a watch.\",cascade_args=cascade_args, return_stats=True, find_top_k=True)\n"
   ],
   "id": "b5f27a75d38cc16c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import *\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=merged_df_filtered_black_footwear,\n",
    "    filtered_df=merged_df_filtered,\n",
    "    article_type=None,\n",
    "    base_colour=None\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "5ba288ea49f13a18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sampling",
   "id": "79fc675e90499e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "363c1ed6f3ac4873",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import importlib\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "importlib.reload(sys.modules['lotus.sem_ops.cascade_utils'])\n",
    "importlib.reload(sys.modules['lotus.sem_ops.sem_filter'])\n",
    "importlib.reload(sys.modules['lotus'])\n",
    "importlib.reload(sys.modules['join_optimizer.join_optimizer.productDisplayName_index.evaluate'])\n",
    "importlib.reload(sys.modules['pandas'])\n",
    "import lotus.sem_ops.sem_filter\n",
    "import lotus\n",
    "\n",
    "# Ensure you import the module (not just the function) so autoreload can update it:\n",
    "import lotus.sem_ops.sem_filter as sem_filter_mod\n"
   ],
   "id": "7cde71f0f9e0acbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.95,\n",
    "    precision_target=0.9,\n",
    "    sampling_percentage=0.1,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    "    cascade_IS_weight=1,\n",
    "    cascade_num_calibration_quantiles = 100,\n",
    "    failure_probability=0.1,\n",
    "    cascade_IS_random_seed=114,\n",
    "    cascade_IS_max_sample_range=444\n",
    "\n",
    ")\n",
    "\n",
    "merged_df_filtered_big =  merged_df.sem_filter(\"{_image} shows a wallet\", cascade_args=cascade_args ,return_stats=False, find_top_k=False)\n"
   ],
   "id": "82def2fdedfe44f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from join_optimizer.join_optimizer.productDisplayName_index.evaluate import *\n",
    "\n",
    "metrics, FP, FN = evaluate_filter(\n",
    "    dataset_df=merged_df_filtered_wallet,\n",
    "    filtered_df=merged_df_filtered_big,\n",
    "    article_type=None,\n",
    "    base_colour=None\n",
    ")\n",
    "print(metrics)"
   ],
   "id": "95dd9b27d9c2da8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Just sim_search",
   "id": "c9245f4a3047d9c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sem_search with similarity scores returned\n",
    "sim_df_with_scores = merged_df.sem_search(\n",
    "    \"_imageURL\",\n",
    "    # \"You will receive an image of a product. Determine whether the product can be worn on the feet, like shoes, sandals, flip-flops, ... The predominant color of the depicted product should be black. If there are multiple products in the picture, always refer to the most promiment one.\",\n",
    "    \"_imageURL the main product in the image is a watch.\",\n",
    "    K=60,\n",
    "    return_scores=True,\n",
    "    suffix=\"_similarity_score\"\n",
    ")\n"
   ],
   "id": "418a238b5b0914f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Joins",
   "id": "405a29efc2db46a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res_sim_join = merged_df_filtered.sem_sim_join(df, left_on='_image', right_on='productDisplayName', K=1, keep_index=True)",
   "id": "648774f9d25b0e72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "expr = \"Does {productDisplayName} exactly and precisely match the {_image}?\"\n",
    "from lotus.types import CascadeArgs, ProxyModel\n",
    "\n",
    "cascade_args = CascadeArgs(\n",
    "    recall_target=0.9,\n",
    "    precision_target=0.75,\n",
    "    sampling_percentage=0.04,\n",
    "    proxy_model=ProxyModel.EMBEDDING_MODEL,\n",
    ")\n",
    "\n",
    "res = merged_df_filtered.sem_join(df, expr,cascade_args=cascade_args, return_stats=True)\n",
    "\n",
    "# print(f\"Joined {df.shape[0]} rows from df1 with {filtered_df2.shape[0]} rows from df2\")\n",
    "# print(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\n",
    "# print(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\n",
    "# print(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\n",
    "# print(f\"Naive join would require {df.shape[0]*df2.shape[0]} LM calls\")\n"
   ],
   "id": "f9d77a583c15e828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = 0",
   "id": "4635aa11d0ed6e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "expr = \"given {productDisplayName}, which {_image} does more exactly and precisely match?\"\n",
    "\n",
    "ranked, stats = res[0].sem_topk(\n",
    "    expr,\n",
    "    K=1,\n",
    "    group_by=[\"productDisplayName\"],\n",
    "    method=\"quick\",\n",
    "    return_stats=True\n",
    ")\n",
    "ranked\n"
   ],
   "id": "1e3d8b09b9168f1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "join_topk = ranked.query('_id == id')\n",
    "sim_1 = res_sim_join.query('_id == id')"
   ],
   "id": "183eb16c180b142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7d3292e4509f3b48",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
